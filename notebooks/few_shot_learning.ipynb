{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot Learning with Presto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Overview \n",
    "\n",
    "1) Short introduction on Foundation Models and Presto\n",
    "2) Definition of Few-Shot learning\n",
    "3) Apply Presto to perfrom Few-Shot learning on a regression and a classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Foundation Models\n",
    "\n",
    "A Foundation Model is a model trained on large and diverse unlabeled datasets to learn general patterns and features of the data. Thanks to its strong generalization capabilities, such a model can be adapted for a wide range of applications that use similar types of input data.\n",
    "\n",
    "**Presto** (**P**retrained **Re**mote **S**ensing **T**ransf**o**rmer) is a foundation model trained on a large, unlabeled dataset of Sentinel-2, Sentinel-1, Meteorological and Topography pixel-timeseries data. It is able to capture long-range relationships across time and sensor dimensions, improving the signal-to-noise ratio and providing a concise, informative representation of the inputs. \n",
    "In this project, We made use of the Presto version developed in collaboration with [WorldCereal](https://github.com/WorldCereal/presto-worldcereal/)\n",
    "\n",
    "Originally trained on monthly composites, Presto has been refined to be able to ingest dekadal data and to be fine-tuned for regression and classification tasks.\n",
    "\n",
    "### 2) Few-Shot Learning\n",
    "\n",
    "Few-shot learning aims to develop models that can learn from a small number of labeled instances while enhancing generalization and performance on new, unseen examples.\n",
    "\n",
    "Given a dataset with only a few annotated examples, we can fine-tune a pretrained foundation model to either directly handle the downstream task or generate compressed representations of the inputs, which can then be used to train a machine learning model for the downstream task.\n",
    "The figure below provides an overview of the latter scenario\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"../images/ScaleAG_pipeline_overview_presto_ml.jpg\" alt=\"Overview of a Foundation Model used to produce embeddings which can be fed as training examples to downstream models for different tasks and applications.\" width=\"700\" />\n",
    "    <p><em>Overview of a Foundation Model used to produce embeddings which can be fed as training examples to downstream models for different tasks and applications.</em></p>\n",
    "</div>\n",
    "\n",
    "### 3) Implementing Few-Shot learning with Presto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vito/millig/miniconda3/envs/sadenv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import catboost as cb\n",
    "from loguru import logger\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(\"/home/vito/millig/gio/prometheo/\")\n",
    "from prometheo.datasets.scaleag import ScaleAgDataset # fix installation\n",
    "from prometheo import finetune\n",
    "from prometheo.finetune import Hyperparams\n",
    "from prometheo.models.presto.wrapper import PretrainedPrestoWrapper, load_pretrained\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from scaleagdata_vito.openeo.extract_sample_scaleag import generate_extraction_job_command\n",
    "from scaleagdata_vito.presto.utils import evaluate_finetuned_model, evaluate_downstream_model, get_encodings\n",
    "from scaleagdata_vito.presto.presto_df import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch data from OpenEO\n",
    "\n",
    "To set up the job, we adapt the job parameters to our needs. The user has to indicate the following fields in order to generate the command to be run in the terminal for starting the extraction \n",
    "\n",
    "```python\n",
    "job_params = dict(\n",
    "    output_folder=..., \n",
    "    input_df=...,\n",
    "    start_date=...,\n",
    "    end_date=...,\n",
    "    unique_id_column=...,\n",
    "    composite_window=..., # \"month\" or \"dekad\" are supported. Default is \"dekad\"\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python scaleag-vito/scripts/extractions/extract.py -output_folder /projects/TAP/HEScaleAgData/data/AVR_subfields/extractions_31012025/ -input_df /home/vito/millig/gio/data/scaleag_extractions/AVR_fields_10000_100000_subfields_yield_bel_nl_roads_removed.geojson --start_date 2022-01-01 --end_date 2022-12-31 --unique_id_column fieldname --composite_window dekad\n"
     ]
    }
   ],
   "source": [
    "job_params = dict(\n",
    "    output_folder=\"/projects/TAP/HEScaleAgData/data/AVR_subfields/extractions_31012025/\",\n",
    "    input_df=\"/home/vito/millig/gio/data/scaleag_extractions/AVR_fields_10000_100000_subfields_yield_bel_nl_roads_removed.geojson\",\n",
    "    start_date=\"2022-01-01\",\n",
    "    end_date=\"2022-12-31\",\n",
    "    unique_id_column=\"fieldname\",\n",
    "    composite_window=\"dekad\",\n",
    ")\n",
    "generate_extraction_job_command(job_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression task: yield estimation \n",
    "\n",
    "Potato yield estimation. The data cover fields in Belgium and The Netherlands during the growing season. \n",
    "In order to test the generalization capabilities of the different models and combinations, we limit data correlation by using data from Belgium as training set and those from The Netherlands as validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 58/284 [00:03<00:13, 16.93it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load extracted dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m window_of_interest \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2022-04-01\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2022-10-31\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles_root_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/projects/TAP/HEScaleAgData/data/AVR_subfields/extractions_31012025/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_of_interest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_of_interest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_valid_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequired_min_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m36\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffer_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_data_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m65535\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomposite_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdekad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gio/scaleag-vito/src/scaleagdata_vito/presto/presto_df.py:738\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(files_root_dir, window_of_interest, use_valid_time, required_min_timesteps, buffer_window, no_data_value, composite_window)\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    737\u001b[0m         _data \u001b[38;5;241m=\u001b[39m extract_window_of_interest(_data, window_of_interest)\n\u001b[0;32m--> 738\u001b[0m _data_pivot \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomposite_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_valid_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_valid_time\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    741\u001b[0m _data_pivot\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    742\u001b[0m df_list\u001b[38;5;241m.\u001b[39mappend(_data_pivot)\n",
      "File \u001b[0;32m~/gio/scaleag-vito/src/scaleagdata_vito/presto/presto_df.py:525\u001b[0m, in \u001b[0;36mprocess_parquet\u001b[0;34m(df, freq, use_valid_time, required_min_timesteps, min_edge_buffer, return_after_fill)\u001b[0m\n\u001b[1;32m    523\u001b[0m df_pivot[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_date\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_pivot[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_date\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    524\u001b[0m df_pivot[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_date\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_pivot[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_date\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m--> 525\u001b[0m df_pivot \u001b[38;5;241m=\u001b[39m \u001b[43mdf_pivot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_pivot\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/pandas/core/frame.py:6115\u001b[0m, in \u001b[0;36mDataFrame.set_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   6112\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   6113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6114\u001b[0m     \u001b[38;5;66;03m# GH 49473 Use \"lazy copy\" with Copy-on-Write\u001b[39;00m\n\u001b[0;32m-> 6115\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   6117\u001b[0m arrays: \u001b[38;5;28mlist\u001b[39m[Index] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   6118\u001b[0m names: \u001b[38;5;28mlist\u001b[39m[Hashable] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/pandas/core/generic.py:6808\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   6659\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   6660\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   6661\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6662\u001b[0m \u001b[38;5;124;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[1;32m   6663\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6806\u001b[0m \u001b[38;5;124;03m    dtype: int64\u001b[39;00m\n\u001b[1;32m   6807\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6808\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[1;32m   6810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(data, axes\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   6811\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6812\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/pandas/core/internals/managers.py:604\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    601\u001b[0m         res\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 604\u001b[0m     \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/pandas/core/internals/managers.py:1786\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1781\u001b[0m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[1;32m   1785\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[0;32m-> 1786\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m \u001b[43m_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1787\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/pandas/core/internals/managers.py:2267\u001b[0m, in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   2265\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2266\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[0;32m-> 2267\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[1;32m   2269\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2270\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[1;32m   2271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/pandas/core/internals/managers.py:2283\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[1;32m   2278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m blocks, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_consolidate:\n\u001b[1;32m   2281\u001b[0m     \u001b[38;5;66;03m# TODO: optimization potential in case all mgrs contain slices and\u001b[39;00m\n\u001b[1;32m   2282\u001b[0m     \u001b[38;5;66;03m# combination of those slices is a slice, too.\u001b[39;00m\n\u001b[0;32m-> 2283\u001b[0m     new_mgr_locs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmgr_locs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2285\u001b[0m     new_values: ArrayLike\n\u001b[1;32m   2287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(blocks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   2288\u001b[0m         \u001b[38;5;66;03m# error: List comprehension has incompatible type List[Union[ndarray,\u001b[39;00m\n\u001b[1;32m   2289\u001b[0m         \u001b[38;5;66;03m# ExtensionArray]]; expected List[Union[complex, generic,\u001b[39;00m\n\u001b[1;32m   2290\u001b[0m         \u001b[38;5;66;03m# Sequence[Union[int, float, complex, str, bytes, generic]],\u001b[39;00m\n\u001b[1;32m   2291\u001b[0m         \u001b[38;5;66;03m# Sequence[Sequence[Any]], SupportsArray]]\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:179\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/numpy/core/multiarray.py:148\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    empty_like(prototype, dtype=None, order='K', subok=True, shape=None)\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m \n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (prototype,)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;129m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath\u001b[38;5;241m.\u001b[39mconcatenate)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcatenate\u001b[39m(arrays, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    150\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m    concatenate((a1, a2, ...), axis=0, out=None, dtype=None, casting=\"same_kind\")\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m \n\u001b[1;32m    241\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# optimize for the typical case where only arrays is provided\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load extracted dataset\n",
    "window_of_interest = [\"2022-04-01\", \"2022-10-31\"]\n",
    "df = load_dataset(\n",
    "    files_root_dir=\"/projects/TAP/HEScaleAgData/data/AVR_subfields/extractions_31012025/\",\n",
    "    window_of_interest=window_of_interest,\n",
    "    use_valid_time=False,\n",
    "    required_min_timesteps=36,\n",
    "    buffer_window=8,\n",
    "    no_data_value=65535,\n",
    "    composite_window=\"dekad\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 11180\n",
      "Val size: 2685\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# split in train and val\n",
    "# df_sample = df.sample(frac=0.1, random_state=42)\n",
    "sampling_frac = 0.8\n",
    "random.seed(3)\n",
    "parentname = df.parentname.unique()\n",
    "parentname_train = random.sample(list(parentname), int(len(parentname)*sampling_frac))\n",
    "df_sample = df.copy()\n",
    "df_train = df_sample[df_sample.parentname.isin(parentname_train)]\n",
    "df_val = df_sample[~df_sample.parentname.isin(parentname_train)]\n",
    "\n",
    "print(f\"Train size: {len(df_train)}\")\n",
    "print(f\"Val size: {len(df_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-07 10:58:10.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprometheo.datasets.scaleag\u001b[0m:\u001b[36mset_num_outputs\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mSetting number of outputs to 1 for regression task.\u001b[0m\n",
      "\u001b[32m2025-02-07 10:58:10.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprometheo.datasets.scaleag\u001b[0m:\u001b[36mset_num_outputs\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mSetting number of outputs to 1 for regression task.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# initialize datasets\n",
    "num_timesteps = df.available_timesteps.max()\n",
    "\n",
    "train_ds = ScaleAgDataset(\n",
    "    df_train,\n",
    "    num_timesteps=num_timesteps,\n",
    "    task_type=\"regression\",\n",
    "    target_name=\"median_yield\",\n",
    "    compositing_window=\"dekad\",\n",
    "    upper_bound=120000,\n",
    "    lower_bound=10000,\n",
    ")\n",
    "val_ds = ScaleAgDataset(\n",
    "    df_val,\n",
    "    num_timesteps=num_timesteps,\n",
    "    task_type=\"regression\",\n",
    "    target_name=\"median_yield\",\n",
    "    compositing_window=\"dekad\",\n",
    "    upper_bound=120000,\n",
    "    lower_bound=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-07 10:58:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprometheo.utils\u001b[0m - \u001b[1mLogging setup complete. Logging to: /home/vito/millig/gio/presto_exp/prometheo_exp/logs/presto-ss-wc-10D-ft-dek.log and console.\u001b[0m\n",
      "\u001b[32m2025-02-07 10:58:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprometheo.finetune\u001b[0m - \u001b[1mUsing output dir: /home/vito/millig/gio/presto_exp/prometheo_exp\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train metric: 0.006, Val metric: 0.005, Best Val Loss: 0.005 (improved):  62%|██████▏   | 31/50 [2:05:00<1:22:02, 259.07s/it]"
     ]
    }
   ],
   "source": [
    "# Construct the model with finetuning head\n",
    "pretrained_model_path = \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/scaleagdata/models/presto-ss-wc_10D.pt\"\n",
    "model = PretrainedPrestoWrapper(\n",
    "    num_outputs=1,\n",
    "    regression=True,\n",
    ")\n",
    "model = load_pretrained(model, pretrained_model_path, strict=False)\n",
    "\n",
    "# Reduce epochs for testing purposes\n",
    "hyperparams = Hyperparams(max_epochs=50, batch_size=256, patience=1, num_workers=2)\n",
    "output_dir = Path(\"/home/vito/millig/gio/presto_exp/prometheo_exp\")\n",
    "\n",
    "# set loss depending on the task type\n",
    "if train_ds.task_type == \"regression\":\n",
    "    loss_fn = nn.MSELoss()\n",
    "elif train_ds.task_type == \"binary\":\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "else:\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "finetuned_model = finetune.run_finetuning(\n",
    "            model,\n",
    "            train_ds,\n",
    "            val_ds,\n",
    "            experiment_name=\"presto-ss-wc-10D-ft-dek\",\n",
    "            output_dir=output_dir,\n",
    "            loss_fn=loss_fn,\n",
    "            hyperparams=hyperparams,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate using end-to-end finetuned Presto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-06 13:11:50.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscaleagdata_vito.presto.utils\u001b[0m:\u001b[36mevaluate_finetuned_model\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mEvaluating the finetuned model on regression task\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': 9361.403876379496,\n",
       " 'R2_score': -0.011486582941066636,\n",
       " 'explained_var_score': -0.011409980070501424,\n",
       " 'MAPE': 0.12428021738426595}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_model = PretrainedPrestoWrapper(num_outputs=1, regression=True)\n",
    "finetuned_model = load_pretrained(\n",
    "    finetuned_model,\n",
    "    \"/home/vito/millig/gio/presto_exp/prometheo_exp/presto-ss-wc-10D-ft-dek.pt\",\n",
    ")\n",
    "\n",
    "evaluate_finetuned_model(finetuned_model, val_ds, num_workers=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train downstream model on Presto encodings and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-04 10:37:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m - \u001b[1mComputing Presto encodings\u001b[0m\n",
      "\u001b[32m2025-02-04 10:39:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m - \u001b[1mFitting Catboost model on Presto encodings\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TBB Warning: The number of workers is currently limited to 1. The request for 95 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7f142883a7d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebook_device = \"GPU\" if torch.cuda.is_available() else None\n",
    "cbm = cb.CatBoostRegressor(\n",
    "    random_state=3,\n",
    "    task_type=notebook_device,\n",
    "    logging_level=\"Silent\",\n",
    "    loss_function=\"RMSE\",\n",
    ")\n",
    "logger.info(\"Computing Presto encodings\")\n",
    "train_dl = DataLoader(train_ds, batch_size=256, shuffle=True, num_workers=2)\n",
    "train_encodings, train_targets = get_encodings(train_dl, finetuned_model)\n",
    "logger.info(\"Fitting Catboost model on Presto encodings\")\n",
    "train_dataset = cb.Pool(train_encodings, train_targets)\n",
    "cbm.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-04 10:39:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscaleagdata_vito.presto.utils\u001b[0m - \u001b[1mEvaluating the finetuned model on regression task\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': 9857.511666240649,\n",
       " 'R2_score': 0.10692120073691003,\n",
       " 'explained_var_score': 0.10769062053643519,\n",
       " 'MAPE': 0.0780827248908144}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_downstream_model(finetuned_model, cbm, val_ds, num_workers=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TBB Warning: The number of workers is currently limited to 1. The request for 95 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7f47fbc69de0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scaleagdata_vito.presto.presto_utils_demo import revert_to_original_units\n",
    "from scaleagdata_vito.demo.utils import prepare_data_for_cb\n",
    "notebook_device = \"GPU\" if torch.cuda.is_available() else None\n",
    "raw_cbm = cb.CatBoostRegressor(\n",
    "    random_state=3,\n",
    "    task_type=notebook_device,\n",
    "    logging_level=\"Silent\",\n",
    "    loss_function=\"RMSE\",\n",
    ")\n",
    "\n",
    "train_x, train_y = prepare_data_for_cb(\n",
    "    df_train,\n",
    "    \"median_yield\",\n",
    "    lower_bound=10000,\n",
    "    upper_bound=120000,\n",
    "    num_time_steps=num_timesteps,\n",
    ")\n",
    "val_x, val_y = prepare_data_for_cb(\n",
    "    df_val, \n",
    "    \"median_yield\",\n",
    "    lower_bound=10000, \n",
    "    upper_bound=120000,\n",
    "    num_time_steps=num_timesteps)\n",
    "\n",
    "train_pool = cb.Pool(train_x, train_y)\n",
    "raw_cbm.fit(train_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, mean_absolute_percentage_error\n",
    "\n",
    "preds = raw_cbm.predict(val_x)\n",
    "targets = revert_to_original_units(\n",
    "    val_y, lower_bound=10000, upper_bound=120000\n",
    ")\n",
    "preds = revert_to_original_units(\n",
    "    preds, lower_bound=10000, upper_bound=120000\n",
    ")\n",
    "metrics = {\n",
    "    \"RMSE\": float(np.sqrt(mean_squared_error(targets, preds))),\n",
    "    \"R2_score\": float(r2_score(targets, preds)),\n",
    "    \"explained_var_score\": float(explained_variance_score(targets, preds)),\n",
    "    \"MAPE\": float(mean_absolute_percentage_error(targets, preds)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RMSE': 13811.234190851072,\n",
       " 'R2_score': 0.6525257053276933,\n",
       " 'explained_var_score': 0.652657666821981,\n",
       " 'MAPE': 0.15791034200182627}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune on crop/no-crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from presto.utils import prep_dataframe, process_parquet\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Tuple, Union\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def split_df(\n",
    "    df: pd.DataFrame,\n",
    "    val_sample_ids: Optional[List[str]] = None,\n",
    "    val_countries_iso3: Optional[List[str]] = None,\n",
    "    val_years: Optional[List[int]] = None,\n",
    "    val_size: Optional[float] = None,\n",
    "    train_only_samples: Optional[List[str]] = None,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    if val_size is not None:\n",
    "        assert (\n",
    "            (val_countries_iso3 is None)\n",
    "            and (val_years is None)\n",
    "            and (val_sample_ids is None)\n",
    "        )\n",
    "        val, train = np.split(\n",
    "            df.sample(frac=1, random_state=42), [int(val_size * len(df))]\n",
    "        )\n",
    "        logger.info(f\"Using {len(train)} train and {len(val)} val samples\")\n",
    "        return pd.DataFrame(train), pd.DataFrame(val)\n",
    "    if val_sample_ids is not None:\n",
    "        assert (val_countries_iso3 is None) and (val_years is None)\n",
    "        is_val = df.sample_id.isin(val_sample_ids)\n",
    "        is_train = ~df.sample_id.isin(val_sample_ids)\n",
    "    elif val_countries_iso3 is not None:\n",
    "        assert (val_sample_ids is None) and (val_years is None)\n",
    "        df = join_with_world_df(df)\n",
    "        for country in val_countries_iso3:\n",
    "            assert df.iso3.str.contains(\n",
    "                country\n",
    "            ).any(), f\"Tried removing {country} but it is not in the dataframe\"\n",
    "        if train_only_samples is not None:\n",
    "            is_val = df.iso3.isin(val_countries_iso3) & ~df.sample_id.isin(\n",
    "                train_only_samples\n",
    "            )\n",
    "        else:\n",
    "            is_val = df.iso3.isin(val_countries_iso3)\n",
    "        is_train = ~df.iso3.isin(val_countries_iso3)\n",
    "    elif val_years is not None:\n",
    "        df[\"end_date_ts\"] = pd.to_datetime(df.end_date)\n",
    "        if train_only_samples is not None:\n",
    "            is_val = df.end_date_ts.dt.year.isin(val_years) & ~df.sample_id.isin(\n",
    "                train_only_samples\n",
    "            )\n",
    "        else:\n",
    "            is_val = df.end_date_ts.dt.year.isin(val_years)\n",
    "        is_train = ~df.end_date_ts.dt.year.isin(val_years)\n",
    "\n",
    "    logger.info(\n",
    "        f\"Using {len(is_val) - sum(is_val)} train and {sum(is_val)} val samples\"\n",
    "    )\n",
    "\n",
    "    return df[is_train], df[is_val]\n",
    "\n",
    "\n",
    "def load_df(\n",
    "    parquet_file: Union[Path, str],\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    logger.info(\"Reading dataset\")\n",
    "    files = sorted(glob(f\"{parquet_file}/**/*.parquet\"))\n",
    "\n",
    "    df_list = []\n",
    "    for f in tqdm(files[:50]):\n",
    "        _data = pd.read_parquet(f, engine=\"fastparquet\")\n",
    "        _ref_id = f.split(\"/\")[-2].split(\"=\")[-1]\n",
    "        _data[\"ref_id\"] = _ref_id\n",
    "        _data_pivot = process_parquet(_data)\n",
    "        _data_pivot.reset_index(inplace=True)\n",
    "        df_list.append(_data_pivot)\n",
    "    df = pd.concat(df_list)\n",
    "    df = df.fillna(65535)\n",
    "    del df_list\n",
    "    return df\n",
    "\n",
    "def prepare_training_df(df, val_samples_file=None):\n",
    "    df = prep_dataframe(df, filter_function=None, dekadal=False).reset_index()\n",
    "\n",
    "    if val_samples_file is not None:\n",
    "        logger.info(f\"Controlled train/test split based on: {val_samples_file}\")\n",
    "        val_samples_df = pd.read_csv(val_samples_file)\n",
    "        train_df, test_df = split_df(\n",
    "            df, val_sample_ids=val_samples_df.sample_id.tolist()\n",
    "        )\n",
    "    else:\n",
    "        logger.info(\"Random train/test split ...\")\n",
    "        train_df, test_df = split_df(df, val_size=0.2)\n",
    "    train_df, val_df = split_df(train_df, val_size=0.2)\n",
    "\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet_file = \"/home/vito/millig/projects/worldcereal/data/worldcereal_training_data_monthly.parquet/worldcereal_training_data.parquet\"\n",
    "files = sorted(glob(f\"{parquet_file}/**/*.parquet\"))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-10 10:33:38.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_df\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mReading dataset\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:04<00:28,  1.51it/s]Dropping 5 faulty samples.\n",
      "100%|██████████| 50/50 [00:33<00:00,  1.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# from scaleagdata_vito.presto.presto_df import process_parquet\n",
    "\n",
    "# Training parameters\n",
    "pretrained_model_path = \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/models/PhaseII/presto-ss-wc_longparquet_random-window-cut_no-time-token_epoch96_corrected-mask.pt\"\n",
    "parquet_file = \"/home/vito/millig/projects/worldcereal/data/worldcereal_training_data_monthly.parquet/worldcereal_training_data.parquet\"\n",
    "val_samples_file = \"/home/vito/millig/gio/worldcereal-classification/scripts/training/finetuning/cropland_random_generalization_test_split_samples.csv\"\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "patience = 5\n",
    "num_workers = 16\n",
    "\n",
    "# ------------------------------------------\n",
    "# Get the train/val/test dataframes\n",
    "df = load_df(parquet_file)\n",
    "\n",
    "# val_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1982928"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = df.sample(frac=0.01,random_state=42)\n",
    "df_sample.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-10 10:37:38.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprepare_training_df\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mControlled train/test split based on: /home/vito/millig/gio/worldcereal-classification/scripts/training/finetuning/cropland_random_generalization_test_split_samples.csv\u001b[0m\n",
      "\u001b[32m2025-02-10 10:37:39.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msplit_df\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mUsing 3895 train and 653 val samples\u001b[0m\n",
      "/home/vito/millig/miniconda3/envs/sadenv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "\u001b[32m2025-02-10 10:37:39.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msplit_df\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mUsing 3116 train and 779 val samples\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(29, 25, 29)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df, test_df = prepare_training_df(df_sample, val_samples_file)\n",
    "train_df.available_timesteps.max(), test_df.available_timesteps.max(), val_df.available_timesteps.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-10 10:37:44.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprometheo.datasets.scaleag\u001b[0m:\u001b[36mset_num_outputs\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mSetting number of outputs to 1 for binary task.\u001b[0m\n",
      "\u001b[32m2025-02-10 10:37:44.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprometheo.datasets.scaleag\u001b[0m:\u001b[36mset_num_outputs\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mSetting number of outputs to 1 for binary task.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# initialize datasets\n",
    "num_timesteps = train_df.available_timesteps.max()\n",
    "\n",
    "train_ds = ScaleAgDataset(\n",
    "    train_df,\n",
    "    num_timesteps=num_timesteps,\n",
    "    task_type=\"binary\",\n",
    "    target_name=\"LANDCOVER_LABEL\",\n",
    "    positive_labels=[10, 11, 12, 13],\n",
    "    compositing_window=\"month\",\n",
    ")\n",
    "val_ds = ScaleAgDataset(\n",
    "    val_df,\n",
    "    num_timesteps=num_timesteps,\n",
    "    task_type=\"binary\",\n",
    "    target_name=\"LANDCOVER_LABEL\",\n",
    "    positive_labels=[10, 11, 12, 13],\n",
    "    compositing_window=\"month\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectTimeout",
     "evalue": "HTTPSConnectionPool(host='artifactory.vgt.vito.be', port=443): Max retries exceeded with url: /artifactory/auxdata-public/worldcereal/models/PhaseII/presto-ss-wc_longparquet_random-window-cut_no-time-token_epoch96_corrected-mask.pt (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f050a71e2f0>, 'Connection to artifactory.vgt.vito.be timed out. (connect timeout=None)'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/urllib3/connection.py:199\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/urllib3/connectionpool.py:490\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    489\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[0;32m--> 490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[1;32m    492\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/urllib3/connectionpool.py:1095\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1095\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/urllib3/connection.py:693\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    692\u001b[0m sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[0;32m--> 693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    694\u001b[0m server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/urllib3/connection.py:208\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    211\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m: (<urllib3.connection.HTTPSConnection object at 0x7f050a71e2f0>, 'Connection to artifactory.vgt.vito.be timed out. (connect timeout=None)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/urllib3/connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='artifactory.vgt.vito.be', port=443): Max retries exceeded with url: /artifactory/auxdata-public/worldcereal/models/PhaseII/presto-ss-wc_longparquet_random-window-cut_no-time-token_epoch96_corrected-mask.pt (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f050a71e2f0>, 'Connection to artifactory.vgt.vito.be timed out. (connect timeout=None)'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m---> 15\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedPrestoWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Set the parameters\u001b[39;00m\n\u001b[1;32m     23\u001b[0m hyperparams \u001b[38;5;241m=\u001b[39m Hyperparams(\n\u001b[1;32m     24\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m     25\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     26\u001b[0m     patience\u001b[38;5;241m=\u001b[39mpatience,\n\u001b[1;32m     27\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39mnum_workers,\n\u001b[1;32m     28\u001b[0m )\n",
      "File \u001b[0;32m~/gio/prometheo/prometheo/models/presto/wrapper.py:294\u001b[0m, in \u001b[0;36mPretrainedPrestoWrapper.__init__\u001b[0;34m(self, num_outputs, regression, pretrained_model_path)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# Load pretrained model before making any adaptations\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pretrained_model_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 294\u001b[0m     presto \u001b[38;5;241m=\u001b[39m \u001b[43mload_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpresto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# Extract the encoder from the original Presto model\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m presto\u001b[38;5;241m.\u001b[39mencoder\n",
      "File \u001b[0;32m~/gio/prometheo/prometheo/models/presto/wrapper.py:248\u001b[0m, in \u001b[0;36mload_pretrained\u001b[0;34m(model, model_path, strict)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load pretrained weights into a Presto model.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m    If the specified model path does not exist.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model_path, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (model_path\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m--> 248\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m     presto_model_layers \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m    250\u001b[0m         io\u001b[38;5;241m.\u001b[39mBytesIO(response\u001b[38;5;241m.\u001b[39mcontent), map_location\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m    251\u001b[0m     )\n\u001b[1;32m    252\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(presto_model_layers, strict\u001b[38;5;241m=\u001b[39mstrict)\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/envs/sadenv/lib/python3.10/site-packages/requests/adapters.py:688\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, NewConnectionError):\n\u001b[0;32m--> 688\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ResponseError):\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RetryError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectTimeout\u001b[0m: HTTPSConnectionPool(host='artifactory.vgt.vito.be', port=443): Max retries exceeded with url: /artifactory/auxdata-public/worldcereal/models/PhaseII/presto-ss-wc_longparquet_random-window-cut_no-time-token_epoch96_corrected-mask.pt (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f050a71e2f0>, 'Connection to artifactory.vgt.vito.be timed out. (connect timeout=None)'))"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.optim import AdamW, lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from prometheo.finetune import Hyperparams, run_finetuning\n",
    "from prometheo.models.presto import param_groups_lrd\n",
    "\n",
    "# set loss depending on the task type\n",
    "if train_ds.task_type == \"regression\":\n",
    "    loss_fn = nn.MSELoss()\n",
    "elif train_ds.task_type == \"binary\":\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "else:\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "model = PretrainedPrestoWrapper(\n",
    "    num_outputs=1,\n",
    "    regression=False,\n",
    "    pretrained_model_path=pretrained_model_path,\n",
    ")\n",
    "\n",
    "# Set the parameters\n",
    "hyperparams = Hyperparams(\n",
    "    max_epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    patience=patience,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "parameters = param_groups_lrd(model)\n",
    "optimizer = AdamW(parameters, lr=hyperparams.lr)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "\n",
    "# Run the finetuning\n",
    "logger.info(\"Starting finetuning...\")\n",
    "finetuned_model = run_finetuning(\n",
    "    model=model,\n",
    "    train_ds=train_ds,\n",
    "    val_ds=val_ds,\n",
    "    experiment_name=\"presto_wc_ft_crop\",\n",
    "    output_dir=output_dir,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    hyperparams=hyperparams,\n",
    "    setup_logging=False,  # Already setup logging\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sadenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
