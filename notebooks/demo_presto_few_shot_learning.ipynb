{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import catboost as cb\n",
    "import os\n",
    "import openeo\n",
    "from loguru import logger\n",
    "import geopandas as gpd\n",
    "import geojson\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from scaleagdata_vito.presto.presto_utils import evaluate\n",
    "from scaleagdata_vito.presto.datasets import ScaleAG10DDataset\n",
    "from scaleagdata_vito.presto.presto_df import (add_labels, xr_to_df, filter_ts)\n",
    "from scaleagdata_vito.presto.presto_utils import load_pretrained_model_from_url, get_encodings\n",
    "from scaleagdata_vito.openeo.preprocessing import run_openeo_extraction_job\n",
    "from openeo_gfmap import (\n",
    "    Backend,\n",
    "    BackendContext,\n",
    "    TemporalContext,\n",
    "    FetchType,\n",
    ")\n",
    "from openeo_gfmap.manager.job_splitters import split_job_hex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Presto pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decadal and Monthly Presto models trained in self-supervised mode on WorldCereal data\n",
    "presto_ss_10d_wc = \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/scaleagdata/models/presto-ss-wc_10D.pt\"\n",
    "presto_ss_30d_wc = \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/scaleagdata/models/presto-ss-wc_30D.pt\"\n",
    "model_wc_10d = load_pretrained_model_from_url(\n",
    "    presto_ss_10d_wc, finetuned=False, ss_dekadal=True, strict=False, device=\"cpu\"\n",
    ")\n",
    "model_wc_30d = load_pretrained_model_from_url(\n",
    "    presto_ss_30d_wc, finetuned=False, ss_dekadal=False, strict=False, device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot learning with Presto on yield task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch data from OpenEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe with labels and polygons we want to extract openeo data for\n",
    "gdf = (\n",
    "    gpd.read_file(\n",
    "        \"/projects/TAP/HEScaleAgData/timeseries_modelling/datasets/apr2024_AVR_subfields/data/AVR_fields_10000_100000_subfields_yield_bel_nl_roads_removed.geojson\"\n",
    "    ).iloc[:100]\n",
    "    .drop(columns=[\"date\"])\n",
    ")\n",
    "\n",
    "# setup OpenEO job parameters\n",
    "job_params = dict(\n",
    "    connection=openeo.connect(\"https://openeo.creo.vito.be/openeo/\").authenticate_oidc(),\n",
    "    backend_context=BackendContext(Backend.CDSE),\n",
    "    temporal_extent=TemporalContext(\n",
    "        start_date=\"2022-01-01\",\n",
    "        end_date=\"2022-12-31\",\n",
    "    ),\n",
    "    fetch_type=FetchType.POINT,\n",
    "    disable_meteo=False,\n",
    "    out_format=\"NetCDF\",\n",
    "    title=\"ScaleAGData_demo\",\n",
    "    split_dataset=False,\n",
    "    output_path=\"/home/vito/millig/gio/data/scaleag_demo/test1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(job_params[\"output_path\"])\n",
    "if not os.path.exists(job_params[\"output_path\"]):\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if job_params[\"split_dataset\"]:\n",
    "    datasets = split_job_hex(gdf)\n",
    "    for i, sub_gdf in enumerate(datasets):\n",
    "        logger.info(f\"Extracting OpenEO data for subset {i}\")\n",
    "        output_path_frame = output_path / f\"cube_{i}\"\n",
    "        output_path_frame.mkdir(parents=True, exist_ok=True)\n",
    "        run_openeo_extraction_job(sub_gdf, str(output_path_frame), job_params)\n",
    "else:\n",
    "    logger.info(f\"Extracting OpenEO data for dataset\")\n",
    "    run_openeo_extraction_job(gdf, str(output_path), job_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Presto on yield task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_file = f\"{output_path}/timeseries.nc\"\n",
    "dataset_file = \"/home/vito/millig/projects/TAP/HEScaleAgData/data/AVR_subfields/avr_subfields_10d.nc\"\n",
    "gdf_label_file = (\n",
    "    \"/projects/TAP/HEScaleAgData/\" \\\n",
    "    \"timeseries_modelling/datasets/apr2024_AVR_subfields/\" \\\n",
    "    \"data/AVR_fields_10000_100000_subfields_yield_bel_nl_roads_removed.geojson\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = add_labels(xr_to_df(dataset_file), gdf_label_file)\n",
    "meteo = [c for c in dataset.columns if \"METEO\" in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split avoiding data leakage\n",
    "np.random.seed(3)\n",
    "df_p = dataset['parentname'].unique()\n",
    "train_frac = 0.90\n",
    "sample_idx = np.random.choice(range(0, len(df_p)), size=int(train_frac*len(df_p)), replace=False)\n",
    "train_df = dataset[dataset['parentname'].isin(df_p[sample_idx])].reset_index(drop=True)\n",
    "val_df = dataset[~dataset['parentname'].isin(df_p[sample_idx])].reset_index(drop=True)\n",
    "\n",
    "print(f\"Validation: number of field IDs: {len(val_df['parentname'].unique())}, number of samples: {len(val_df)}\")\n",
    "print(f\"Training: number of field IDs: {len(train_df['parentname'].unique())}, number of samples: {len(train_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = \"median_yield\"\n",
    "train_ds = ScaleAG10DDataset(train_df, target_name=target_name, task=\"regression\")\n",
    "val_ds = ScaleAG10DDataset(val_df, target_name=target_name, task=\"regression\")\n",
    "\n",
    "dl_train = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "dl_val = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"presto-ss-wc_10D\"\n",
    "encodings_np, targets = get_encodings(dl_train, model_wc_10d)\n",
    "\n",
    "logger.info(f\"Fitting Catboost model with {model_name} encodings\")\n",
    "\n",
    "cbm = cb.CatBoostRegressor(\n",
    "    random_state=3,\n",
    "    task_type=\"GPU\",\n",
    "    devices=\"0:1\",\n",
    "    logging_level=\"Silent\",\n",
    "    loss_function=\"RMSE\",\n",
    ")\n",
    "train_dataset = cb.Pool(encodings_np, targets)\n",
    "cbm.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, preds, targets = evaluate(\n",
    "    model_wc_10d,\n",
    "    cbm,\n",
    "    dl_val,\n",
    "    task=\"regression\",\n",
    "    up_val=120000,\n",
    "    low_val=10000,\n",
    "    )\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few shot learning with Presto on Crop/no-Crop task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from presto.dataset import WorldCerealLabelled10DDataset\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load WorldCereal dataset from artifactory\n",
    "\n",
    "wc_train_dataset = pd.read_parquet(\n",
    "    \"/home/vito/millig/gio/data/presto_ft/rawts-10d_train.parquet\"\n",
    ")\n",
    "\n",
    "wc_val_dataset = pd.read_parquet(\n",
    "    \"/home/vito/millig/gio/data/presto_ft/rawts-10d_val.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_train_dataset = wc_train_dataset.sample(frac=0.005)\n",
    "wc_val_dataset = wc_val_dataset.sample(frac=0.005)\n",
    "\n",
    "print(len(wc_train_dataset), len(wc_val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_train_ds = WorldCerealLabelled10DDataset(wc_train_dataset)\n",
    "wc_val_ds = WorldCerealLabelled10DDataset(wc_val_dataset)\n",
    "wc_dl_train = DataLoader(\n",
    "    wc_train_ds,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "wc_dl_val = DataLoader(\n",
    "    wc_val_ds,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"presto-ss-wc_10D\"\n",
    "encodings_train, target_train = get_encodings(wc_dl_train, model_wc_10d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Fitting Catboost model with {model_name} encodings\")\n",
    "\n",
    "cbm = cb.CatBoostClassifier(\n",
    "    random_state=3,\n",
    "    task_type=\"GPU\",\n",
    "    devices=\"0:1\",\n",
    "    logging_level=\"Silent\",\n",
    ")\n",
    "train_dataset = cb.Pool(encodings_train, target_train)\n",
    "cbm.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_test, targets_test = get_encodings(wc_dl_val, model_wc_10d)\n",
    "preds_test = cbm.predict(encodings_test)\n",
    "print(classification_report(targets_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sadenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
